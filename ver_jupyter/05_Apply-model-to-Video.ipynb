{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예측 : 저장된 비디오의 경우\n",
    "* 이전의 MobileNet, 훈련된 LSTM 모델을 사용하여 저장된 비디오 파일(.avi, .mp4)의 폭력을 예측하여 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:24:41.707649Z",
     "iopub.status.busy": "2021-05-11T02:24:41.707649Z",
     "iopub.status.idle": "2021-05-11T02:25:05.586551Z",
     "shell.execute_reply": "2021-05-11T02:25:05.586551Z",
     "shell.execute_reply.started": "2021-05-11T02:24:41.707649Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 # openCV 4.5.1\n",
    "import numpy as np # numpy 배열\n",
    "import os # 파일 및 폴더의 경로 지정을 위한 모듈\n",
    "import tensorflow as tf # 텐서플로우\n",
    "from tensorflow import keras # 케라스\n",
    "import time #프로세스 소요시간 표시 목적\n",
    "\n",
    "from skimage.io import imread #이미지 보이기\n",
    "from skimage.transform import resize # 이미지 리사이즈\n",
    "\n",
    "from PIL import Image, ImageFont, ImageDraw #자막 투입 목적\n",
    "from io import BytesIO\n",
    "\n",
    "from collections import deque #비디오 영상에 텍스트 씌워 저장하기에 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러오기\n",
    "* 01~03 의 과정을 거쳐 저장된 모델을 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지를 투입할 베이스 모델(MobileNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:05.587429Z",
     "iopub.status.busy": "2021-05-11T02:25:05.587429Z",
     "iopub.status.idle": "2021-05-11T02:25:06.200785Z",
     "shell.execute_reply": "2021-05-11T02:25:06.200785Z",
     "shell.execute_reply.started": "2021-05-11T02:25:05.587429Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_model=keras.applications.mobilenet.MobileNet(input_shape=(160, 160, 3),\n",
    "                                                  include_top=False,\n",
    "                                                  weights='imagenet', classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과거 훈련시킨 LSTM 모델(.h5)불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:06.201803Z",
     "iopub.status.busy": "2021-05-11T02:25:06.201803Z",
     "iopub.status.idle": "2021-05-11T02:25:08.747439Z",
     "shell.execute_reply": "2021-05-11T02:25:08.746474Z",
     "shell.execute_reply.started": "2021-05-11T02:25:06.201803Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=keras.models.load_model('210508_vc_MobileNet_model_epoch100.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요 함수 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 : 비디오 파일 열기 > 스케일링, 리사이징\n",
    "* 비디오 파일을 불러와 각 프레임들을 넘파이 배열로 변환하여 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:08.748467Z",
     "iopub.status.busy": "2021-05-11T02:25:08.748467Z",
     "iopub.status.idle": "2021-05-11T02:25:08.763424Z",
     "shell.execute_reply": "2021-05-11T02:25:08.762399Z",
     "shell.execute_reply.started": "2021-05-11T02:25:08.748467Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def video_reader(cv2, filename):\n",
    "    \"\"\"비디오 파일 1개를 불러와 각 장면과 프레임을 읽고,\n",
    "    (frame, 160, 160, 3) 크기의 배열로 리사이징한 뒤,\n",
    "    해당 프레임들을 반환\"\"\"\n",
    "    frames=np.zeros((30, 160, 160, 3), dtype=np.float)\n",
    "    #> (비디오파일 개수, 프레임 개수, 사이즈, 사이즈, RGB)\n",
    "    i=0\n",
    "    print(frames.shape)\n",
    "    vc=cv2.VideoCapture(filename) # 비디오 파일로부터 프레임별 이미지 읽어오기\n",
    "    \n",
    "    if vc.isOpened(): #비디오 파일이 열려있으면\n",
    "        rval, frame=vc.read() #영상의 프레임, 값 추출\n",
    "    else:\n",
    "        rval=False\n",
    "    \n",
    "    frm=resize(frame,(160, 160, 3))\n",
    "    frm=np.expand_dims(frm, axis=0)\n",
    "    \n",
    "    if(np.max(frm)>1):\n",
    "        frm=frm/255.0 #프레임의 RGB 값을 스케일링 합니다\n",
    "    frames[i][:]=frm\n",
    "    i+=1\n",
    "    print('Reading Video')\n",
    "    \n",
    "    while i<30:\n",
    "        rval, frame=vc.read()\n",
    "        frm=resize(frame, (160, 160, 3)) #영상을 ()\n",
    "        frm=np.expand_dims(frm, axis=0)\n",
    "        if(np.max(frm)>1):\n",
    "            frm=frm/255.0\n",
    "        frames[i][:]=frm\n",
    "        i+=1\n",
    "        \n",
    "    return frames #> 비디오를 읽어 (30, 160, 160, 3) 배열을 리턴한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 : MobileNet로 프레임별 특성 추출\n",
    "* base_model에 각 프레임을 투입하여, 특성 배열을 추출\n",
    "* 추출한 프레임 이미지별 특성 배열을 훈련된 LSTM모델에 투입할 수 있도록 1차원 배열로 변환함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:08.764428Z",
     "iopub.status.busy": "2021-05-11T02:25:08.764428Z",
     "iopub.status.idle": "2021-05-11T02:25:08.779354Z",
     "shell.execute_reply": "2021-05-11T02:25:08.778373Z",
     "shell.execute_reply.started": "2021-05-11T02:25:08.764428Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_pred_imgarr(base_model, video_frm_ar):\n",
    "    \"\"\"함수 video_reader()사용 결과물을 투입\n",
    "    base_model(MobileNet)이 프레임별로 특성을 추출해 준 뒤,\n",
    "    추출된 프레임 이미지별 특성 배열을\n",
    "    훈련된 LSTM모델에 투입가능한 형태(1차원 배열)로 변환해 줌\"\"\"\n",
    "    # video_frm_ar을 차원 확장 : (30, 160, 160, 3) 투입\n",
    "    #data=[]\n",
    "    #data.append(video_frm_ar)\n",
    "    #video_frm_ar_dim=np.array(data)\n",
    "    video_frm_ar_dim=np.zeros((1, 30, 160, 160, 3), dtype=np.float)\n",
    "    video_frm_ar_dim[0][:][:]=video_frm_ar #> (1, 30, 160, 160, 3)\n",
    "     \n",
    "    # MobileNet으로 각 프레임 이미지로부터 특성 배열 추출\n",
    "    pred_imgarr=base_model.predict(video_frm_ar)\n",
    "    # 추출된 특성 배열을 1차원으로 변환: (1, 프레임 수, 25600)\n",
    "    pred_imgarr=pred_imgarr.reshape(1, pred_imgarr.shape[0], 5*5*1024)\n",
    "    \n",
    "    return pred_imgarr #> ex : (1, 30, 25600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수: 폭력여부 판별\n",
    "* 1차원으로 변환된 프레임별 특성 배열을 투입 훈련된 LSTM모델에 투입\n",
    "* 모델로부터 폭력인지/비폭력인지 여부 판별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:08.780350Z",
     "iopub.status.busy": "2021-05-11T02:25:08.780350Z",
     "iopub.status.idle": "2021-05-11T02:25:08.795311Z",
     "shell.execute_reply": "2021-05-11T02:25:08.794314Z",
     "shell.execute_reply.started": "2021-05-11T02:25:08.780350Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pred_fight(model, pred_imgarr, acuracy=0.9):\n",
    "    \"\"\"예측값이 지정 acuracy이상이면 'True'(폭력)를,\n",
    "    그 미만이면 False(비폭력) 반환.\n",
    "    \n",
    "    ::model:: 훈련된 LSTM 모델(불러오기)\n",
    "    ::pred_imgarr:: (1, 30, 25600) 형태, 1개 영상의 추출된 특성\n",
    "    ::accuracy:: 0.9가 디폴트값. 임의의 값 지정 가능\"\"\"\n",
    "\n",
    "    pred_test=model.predict(pred_imgarr)\n",
    "    #> [0,1](폭력) 또는 [1,0](비폭력)으로 설정되었음에 유의!\n",
    "    \n",
    "    if pred_test[0][1] >= acuracy:\n",
    "        return True, pred_test[0][1] #> True, 폭력일 확률\n",
    "    \n",
    "    else:\n",
    "        return False, pred_test[0][1] #> False, 폭력일 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수 기능 검사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:08.796307Z",
     "iopub.status.busy": "2021-05-11T02:25:08.796307Z",
     "iopub.status.idle": "2021-05-11T02:25:08.811273Z",
     "shell.execute_reply": "2021-05-11T02:25:08.810270Z",
     "shell.execute_reply.started": "2021-05-11T02:25:08.796307Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_file='Fight_itwill_210506_01.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:08.812265Z",
     "iopub.status.busy": "2021-05-11T02:25:08.812265Z",
     "iopub.status.idle": "2021-05-11T02:25:11.219381Z",
     "shell.execute_reply": "2021-05-11T02:25:11.219381Z",
     "shell.execute_reply.started": "2021-05-11T02:25:08.812265Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 160, 160, 3)\n",
      "Reading Video\n"
     ]
    }
   ],
   "source": [
    "video_frm_ar=video_reader(cv2, video_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:11.220378Z",
     "iopub.status.busy": "2021-05-11T02:25:11.220378Z",
     "iopub.status.idle": "2021-05-11T02:25:11.885930Z",
     "shell.execute_reply": "2021-05-11T02:25:11.884932Z",
     "shell.execute_reply.started": "2021-05-11T02:25:11.220378Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30, 25600)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_imgarr=create_pred_imgarr(base_model, video_frm_ar)\n",
    "pred_imgarr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:11.886929Z",
     "iopub.status.busy": "2021-05-11T02:25:11.886929Z",
     "iopub.status.idle": "2021-05-11T02:25:12.471363Z",
     "shell.execute_reply": "2021-05-11T02:25:12.471363Z",
     "shell.execute_reply.started": "2021-05-11T02:25:11.886929Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 0.99869007)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds=pred_fight(model, pred_imgarr, 0.9)\n",
    "preds\n",
    "#> 폭력. 폭력일 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비디오 파일 투입, 폭력여부 판별\n",
    "* 비디오 파일(.mp4) 1개 투입 > 폭력 여부(True/False) 및 폭력일 확률 출력\n",
    "* 정의한 3개의 함수를 모두 사용하여 결과 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:12.472361Z",
     "iopub.status.busy": "2021-05-11T02:25:12.472361Z",
     "iopub.status.idle": "2021-05-11T02:25:12.486323Z",
     "shell.execute_reply": "2021-05-11T02:25:12.486323Z",
     "shell.execute_reply.started": "2021-05-11T02:25:12.472361Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main_fight(video):\n",
    "    \"\"\"1개의 영상을 넣고 정의한 3개의 함수를 모두 사용하여 결과 도출\n",
    "    video_reader() : openCV를 사용해 비디오 불러옴\n",
    "    create_pred_imgarr() : MobileNet으로 이미지별 특성값 저장\n",
    "    pred_fight() : 훈련된 LSTM모델로 폭력여부 예측\"\"\"\n",
    "    \n",
    "    # video_reader()함수로 비디오 읽기\n",
    "    video_frm_ar=video_reader(cv2, video) \n",
    "    # 읽어온 비디오를 VGG19로 특성을 추출하고 알맞게 형변환\n",
    "    pred_imgarr=create_pred_imgarr(base_model, video_frm_ar)\n",
    "    #datav=np.zeros((1, 30, 160, 160, 3), dtype=np.float)\n",
    "    #datav[0][:][:]=vid\n",
    "    \n",
    "    millis=int(round(time.time()*1000)) #> 프로세스 시작시각\n",
    "    \n",
    "    # LSTM 모델(model)에 데이터를 투입, 65%이상이면 폭력으로 표시\n",
    "    f, precent=pred_fight(model, pred_imgarr, acuracy=0.65)\n",
    "    \n",
    "    millis2=int(round(time.time()*1000)) #> 프로세스 종료시각\n",
    "    \n",
    "    res_fight={'Violence': f, #> 폭력(True), 비폭력(False)\n",
    "               'Violence Estimation': str(precent), # 폭력확률\n",
    "               'Processing Time' : str(millis2-millis)} #> 소요시간\n",
    "    \n",
    "    return res_fight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T02:25:12.487321Z",
     "iopub.status.busy": "2021-05-11T02:25:12.487321Z",
     "iopub.status.idle": "2021-05-11T02:25:15.067789Z",
     "shell.execute_reply": "2021-05-11T02:25:15.067789Z",
     "shell.execute_reply.started": "2021-05-11T02:25:12.487321Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 160, 160, 3)\n",
      "Reading Video\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Violence': True,\n",
       " 'Violence Estimation': '0.99869007',\n",
       " 'Processing Time': '148'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영상을 넣은 경우\n",
    "video_file='Fight_itwill_210506_01.mp4'\n",
    "main_fight(video_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비디오 영상에 텍스트 씌워 저장하기\n",
    "* collections 모듈의 deque(데크)double-ended queue 의 줄임말로, 앞과 뒤에서 즉, 양방향에서 데이터를 처리할 수 있는 queue형 자료구조입니다.\n",
    "* 파이썬에서의 리스트와 다루는 법이 유사한 편입니다.\n",
    "* deque 참고 : https://excelsior-cjh.tistory.com/96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 투입 비디오 설정(input)\n",
    "* **주의!** 투입 비디오 프레임 수는 반드시 **30**이어야 합니다. 29.97 안됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T04:21:59.807766Z",
     "iopub.status.busy": "2021-05-11T04:21:59.807766Z",
     "iopub.status.idle": "2021-05-11T04:21:59.820731Z",
     "shell.execute_reply": "2021-05-11T04:21:59.820731Z",
     "shell.execute_reply.started": "2021-05-11T04:21:59.807766Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_path='Fight_itwill_210506_05.mp4' # 투입할 동영상 파일 이름 및 경로\n",
    "output_path=f'{input_path}+output.mp4' #폭력 여부 감별 후 자막을 씌워 저장할 파일 이름 및 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-11T04:22:00.687564Z",
     "iopub.status.busy": "2021-05-11T04:22:00.686566Z",
     "iopub.status.idle": "2021-05-11T04:23:40.674141Z",
     "shell.execute_reply": "2021-05-11T04:23:40.674141Z",
     "shell.execute_reply.started": "2021-05-11T04:22:00.687564Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps : 30.061038063436285\n",
      "preds:[[2.2413046e-04 9.9977583e-01]]\n",
      "Results = [[nan nan]]\n",
      "Maximum Probability : nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-bf36c8d9aed1>:65: RuntimeWarning: Mean of empty slice.\n",
      "  results=np.array(Q)[:i].mean(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[[0.00478598 0.995214  ]]\n",
      "Results = [[2.2413046e-04 9.9977583e-01]]\n",
      "Maximum Probability : 0.9997758269309998\n",
      "\n",
      "preds:[[7.171974e-04 9.992828e-01]]\n",
      "Results = [[0.00250505 0.99749494]]\n",
      "Maximum Probability : 0.9974949359893799\n",
      "\n",
      "preds:[[1.7574173e-04 9.9982435e-01]]\n",
      "Results = [[0.0019091 0.9980909]]\n",
      "Maximum Probability : 0.998090922832489\n",
      "\n",
      "preds:[[5.1806617e-04 9.9948198e-01]]\n",
      "Results = [[0.00147576 0.99852425]]\n",
      "Maximum Probability : 0.9985242486000061\n",
      "\n",
      "preds:[[0.00106501 0.9989349 ]]\n",
      "Results = [[0.00128422 0.99871576]]\n",
      "Maximum Probability : 0.9987157583236694\n",
      "\n",
      "preds:[[0.0015095  0.99849045]]\n",
      "Results = [[0.0014524  0.99854755]]\n",
      "Maximum Probability : 0.9985475540161133\n",
      "\n",
      "preds:[[4.4945168e-04 9.9955052e-01]]\n",
      "Results = [[7.9710456e-04 9.9920291e-01]]\n",
      "Maximum Probability : 0.9992029070854187\n",
      "\n",
      "preds:[[7.523823e-05 9.999248e-01]]\n",
      "Results = [[7.4355537e-04 9.9925643e-01]]\n",
      "Maximum Probability : 0.999256432056427\n",
      "\n",
      "preds:[[5.567938e-05 9.999443e-01]]\n",
      "Results = [[7.2345464e-04 9.9927652e-01]]\n",
      "Maximum Probability : 0.9992765188217163\n",
      "\n",
      "preds:[[5.4174510e-04 9.9945825e-01]]\n",
      "Results = [[6.3097727e-04 9.9936897e-01]]\n",
      "Maximum Probability : 0.9993689656257629\n",
      "\n",
      "preds:[[1.6276044e-04 9.9983716e-01]]\n",
      "Results = [[5.2632357e-04 9.9947369e-01]]\n",
      "Maximum Probability : 0.9994736909866333\n",
      "\n",
      "preds:[[0.00466873 0.9953312 ]]\n",
      "Results = [[2.5697495e-04 9.9974310e-01]]\n",
      "Maximum Probability : 0.9997431039810181\n",
      "\n",
      "preds:[[0.00164434 0.9983557 ]]\n",
      "Results = [[0.00110083 0.99889916]]\n",
      "Maximum Probability : 0.9988991618156433\n",
      "\n",
      "preds:[[0.00338764 0.99661237]]\n",
      "Results = [[0.00141465 0.99858534]]\n",
      "Maximum Probability : 0.9985853433609009\n",
      "\n",
      "preds:[[0.00443199 0.995568  ]]\n",
      "Results = [[0.00208104 0.99791896]]\n",
      "Maximum Probability : 0.997918963432312\n",
      "\n",
      "preds:[[6.745212e-04 9.993255e-01]]\n",
      "Results = [[0.00285909 0.9971409 ]]\n",
      "Maximum Probability : 0.9971408843994141\n",
      "\n",
      "preds:[[0.02375322 0.9762467 ]]\n",
      "Results = [[0.00296145 0.99703854]]\n",
      "Maximum Probability : 0.9970385432243347\n",
      "\n",
      "preds:[[0.06798141 0.9320186 ]]\n",
      "Results = [[0.00677834 0.99322164]]\n",
      "Maximum Probability : 0.993221640586853\n",
      "\n",
      "preds:[[3.8083564e-04 9.9961913e-01]]\n",
      "Results = [[0.02004576 0.97995424]]\n",
      "Maximum Probability : 0.9799542427062988\n",
      "\n",
      "preds:[[5.607391e-04 9.994393e-01]]\n",
      "Results = [[0.01944439 0.98055565]]\n",
      "Maximum Probability : 0.9805556535720825\n",
      "\n",
      "preds:[[0.01694237 0.9830577 ]]\n",
      "Results = [[0.01867015 0.9813298 ]]\n",
      "Maximum Probability : 0.9813297986984253\n",
      "\n",
      "preds:[[0.00746863 0.99253136]]\n",
      "Results = [[0.02192372 0.9780763 ]]\n",
      "Maximum Probability : 0.9780762791633606\n",
      "\n",
      "프레임이 없습니다. 스트리밍을 종료합니다.\n",
      "종료 처리되었습니다. 메모리를 해제합니다.\n"
     ]
    }
   ],
   "source": [
    "#. ----- 비디오 스트리밍을 불러오기 & 초기설정 -----\n",
    "vc=cv2.VideoCapture(input_path)\n",
    "fps=vc.get(cv2.CAP_PROP_FPS) # input_path의 초당 프레임 수 인식. fps=30.0\n",
    "print(f'fps : {fps}')\n",
    "\n",
    "writer=None\n",
    "(W, H)=(None, None)\n",
    "i=0 # 비디오 초 번호. While loop를 돌아가는 회차\n",
    "Q=deque(maxlen=128) \n",
    "\n",
    "video_frm_ar=np.zeros((1, int(fps), 160, 160, 3), dtype=np.float) #frames\n",
    "frame_counter=0 # 1초당 프레임 번호. 1~30\n",
    "frame_list=[] \n",
    "preds=None\n",
    "maxprob=None\n",
    "\n",
    "#. While loop : 스트리밍이 끝날 때까지 프레임 추출 반복문 시작\n",
    "# ----- 스트리밍 동영상들을 (30, 160, 160, 3)으로 저장하기 시작 -----\n",
    "while True: \n",
    "    frame_counter+=1\n",
    "    grabbed, frm=vc.read() # 비디오를 1개 프레임씩 읽는다.\n",
    "    #> grabbed=True, frm=프레임별 넘파이 배열. (240, 320, 3)\n",
    "    \n",
    "    if not grabbed: # 프레임이 안 잡힐 경우\n",
    "        print('프레임이 없습니다. 스트리밍을 종료합니다.')\n",
    "        break\n",
    "            \n",
    "    #if fps!=30: #비디오 fps가 30이 아니면 루프를 돌지 않기로 한다.\n",
    "        #print('비디오의 초당 프레임이 30이 아닙니다. fps=30으로 맞춰주세요.')\n",
    "        #break\n",
    "        \n",
    "    if W is None or H is None: # 프레임 이미지 폭(W), 높이(H)를 동영상에서\n",
    "        (H, W)=frm.shape[:2]\n",
    "            \n",
    "    output=frm.copy() #비디오 프레임을 그대로 복사. 저장/출력할 .mp4 파일로\n",
    "    \n",
    "    frame=resize(frm, (160, 160, 3)) #> input 배열을 (160, 160, 3)으로 변환\n",
    "    frame_list.append(frame) #각 프레임 배열 (160, 160, 3)이 append 된다.\n",
    "        \n",
    "    if frame_counter>=fps: #프레임 카운터가 30이 된 순간. len(frame_list)==30이 된 순간.\n",
    "        #. ----- 1초=30프레임마다 묶어서 예측(.predict) -----\n",
    "        #. ----- 1초 동안 (1, 30, 160, 160, 3) 배열을 만들어 모델에 투입 ---\n",
    "        #. ----- 예측 결과(1초)를 output에 씌워 준다. -----\n",
    "        # 그러기 위해서는 30개씩 append한 리스트를 넘파이화 -> 예측 -> 리스트 초기화 과정이 필요\n",
    "        frame_ar=np.array(frame_list, dtype=np.float16) #> 30개의 원소가 든 리스트를 변환. (30, 160, 160, 3)\n",
    "        frame_list=[] #30프레임이 채워질 때마다 넘파이 배열로 변환을 마친 프레임 리스트는 초기화 해 준다.\n",
    "            \n",
    "        if(np.max(frame_ar)>1): # 넘파이 배열의 RGB 값을 스케일링\n",
    "            frame_ar=frame_ar/255.0\n",
    "            \n",
    "        #video_frm_ar[i][:]=frame_ar #> (i, fps, 160, 160, 3). i번째 1초짜리 영상(30프레임) 배열 파일이 된다.\n",
    "        #print(video_frm_ar.shape)\n",
    "        \n",
    "        #MobileNet로 초당 프레임 이미지 배열로부터 특성 추출 : (1*30, 5, 5, 1024)\n",
    "        pred_imgarr=base_model.predict(frame_ar) #> (30, 5, 5, 1024)\n",
    "        # 추출된 특성 배열들을 1차원으로 변환 : (1, 30, 5*5*1024)\n",
    "        pred_imgarr_dim=pred_imgarr.reshape(1, pred_imgarr.shape[0], 5*5*1024)#> (1, 30, 25600)\n",
    "        # 각 프레임 폭력 여부 예측값을 0에 저장\n",
    "        preds=model.predict(pred_imgarr_dim) #> (True, 0.99) : (폭력여부, 폭력확률)\n",
    "        print(f'preds:{preds}')\n",
    "        Q.append(preds) #> Deque Q에 리스트처럼 예측값을 추가함\n",
    "    \n",
    "        # 지난 5초간의 폭력 확률 평균을 result로 한다.\n",
    "        if i<5:\n",
    "            results=np.array(Q)[:i].mean(axis=0)\n",
    "        else:\n",
    "            results=np.array(Q)[(i-5):i].mean(axis=0)\n",
    "        #results=np.array(Q).mean(axis=0)\n",
    "        print(f'Results = {results}') #> ex : (0.6, 0.650)\n",
    "            \n",
    "        #예측 결과에서 최대폭력확률값\n",
    "        maxprob=np.max(results) #> 가장 높은 값을 선택함\n",
    "        print(f'Maximum Probability : {maxprob}')\n",
    "        print('')\n",
    "            \n",
    "        rest=1-maxprob # 폭력이 아닐 확률\n",
    "        diff=maxprob-rest # 폭력일 확률과 폭력이 아닐 확률의 차이\n",
    "        th=100\n",
    "            \n",
    "        if diff>0.80: # 폭력일 확률과 아닐 확률의 차이가 0.8 이상이면\n",
    "            th=diff #근거가?\n",
    "        \n",
    "        frame_counter=0 #> 1초(30프레임)가 경과했으므로 frame_counter=0으로 리셋\n",
    "        i+=1 #> 1초 경과 의미\n",
    "        \n",
    "        # frame_counter==30이 되면 0으로 돌아가 위 루프를 반복해 준다.\n",
    "                \n",
    "    # ----- output에 씌울 자막 설정하기 -----\n",
    "    # 30프레임(1초)마다 갱신된 값이 output에 씌워지게 된다\n",
    "    font1=ImageFont.truetype('fonts/Raleway-ExtraBold.ttf', int(0.05*W))\n",
    "    font2=ImageFont.truetype('fonts/Raleway-ExtraBold.ttf', int(0.1*W))\n",
    "    \n",
    "    if preds is not None and maxprob is not None: # 예측값이 발생한 후부터\n",
    "        if (preds[0][1])<th : #> 폭력일 확률이 th보다 작으면 정상\n",
    "            text1_1='Normal'\n",
    "            text1_2='{:.2f}%'.format(100-(maxprob*100))\n",
    "            #cv2.putText(output, text1_1, (int(0.025*W), int(0.1*H)),font, fontScale, (0, 255, 0), 2)\n",
    "            #cv2.putText(output, text1_2, (int(0.025*W), int(0.2*H)),font, fontScale, (0, 255, 0), 2)\n",
    "            img_pil=Image.fromarray(output)\n",
    "            draw=ImageDraw.Draw(img_pil)\n",
    "            draw.text((int(0.025*W), int(0.025*H)), text1_1, font=font1, fill=(0,255,0,0))\n",
    "            draw.text((int(0.025*W), int(0.095*H)), text1_2, font=font2, fill=(0,255,0,0))\n",
    "            output=np.array(img_pil)\n",
    "            # cv2.putText(이미지파일, 출력문자, 시작위치좌표(좌측하단), 폰트, 폰트크기, 폰트색상, 폰트두께)\n",
    "                \n",
    "        else : #> 폭력일 확률이 th보다 크면 폭력 취급\n",
    "            text2_1='Violence Alert!'\n",
    "            text2_2='{:.2f}%'.format(maxprob*100)\n",
    "            #cv2.putText(output, text2_1, (int(0.025*W), int(0.1*H)),font, fontScale, (0, 0, 255), 2)\n",
    "            #cv2.putText(output, text2_2, (int(0.025*W), int(0.2*H)),font, fontScale, (0, 0, 255), 2) \n",
    "            img_pil=Image.fromarray(output)\n",
    "            draw=ImageDraw.Draw(img_pil)\n",
    "            draw.text((int(0.025*W), int(0.025*H)), text2_1, font=font1, fill=(0,0,255,0))\n",
    "            draw.text((int(0.025*W), int(0.095*H)), text2_2, font=font2, fill=(0,0,255,0))\n",
    "            output=np.array(img_pil)\n",
    "        \n",
    "    # 자막이 씌워진 동영상을 writer로 저장함\n",
    "    if writer is None:\n",
    "        fourcc=cv2.VideoWriter_fourcc(*'DIVX')\n",
    "        writer=cv2.VideoWriter(output_path, fourcc, 30, (W, H), True)\n",
    "            \n",
    "    # 아웃풋을 새창으로 열어 보여주기\n",
    "    cv2.imshow('This is output', output)\n",
    "    writer.write(output) #output_path로 output 객체를 저장함\n",
    "        \n",
    "    key=cv2.waitKey(round(1000/fps)) # 프레임-다음 프레임 사이 간격\n",
    "    if key==27: # esc 키를 누르면 루프로부터 벗어나고 output 파일이 저장됨\n",
    "        print('ESC키를 눌렀습니다. 녹화를 종료합니다.')\n",
    "        break\n",
    "    \n",
    "print('종료 처리되었습니다. 메모리를 해제합니다.')\n",
    "writer.release()\n",
    "vc.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
