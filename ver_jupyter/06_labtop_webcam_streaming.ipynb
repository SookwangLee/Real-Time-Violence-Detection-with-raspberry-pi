{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실시간 스트리밍 예측 1 : 노트북 웹캠\n",
    "* 노트북 웹캠에서 받아온 영상을 스트리밍하여 실시간으로 예측 출력하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T15:10:53.236116Z",
     "iopub.status.busy": "2021-05-10T15:10:53.236116Z",
     "iopub.status.idle": "2021-05-10T15:11:20.320255Z",
     "shell.execute_reply": "2021-05-10T15:11:20.314374Z",
     "shell.execute_reply.started": "2021-05-10T15:10:53.236116Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 # openCV 4.5.1\n",
    "import numpy as np # numpy 배열\n",
    "import os # 파일 및 폴더의 경로 지정을 위한 모듈\n",
    "import tensorflow as tf # 텐서플로우\n",
    "from tensorflow import keras # 케라스\n",
    "import time #프로세스 소요시간 표시 목적\n",
    "\n",
    "from skimage.io import imread #이미지 보이기\n",
    "from skimage.transform import resize # 이미지 리사이즈\n",
    "\n",
    "from PIL import Image, ImageFont, ImageDraw #자막 투입 목적\n",
    "from io import BytesIO\n",
    "\n",
    "from collections import deque #비디오 영상에 텍스트 씌워 저장하기에 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 불러오기\n",
    "* 01~03 의 과정을 거쳐 저장된 모델을 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지를 투입할 베이스 모델(MobileNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T15:11:20.323246Z",
     "iopub.status.busy": "2021-05-10T15:11:20.323246Z",
     "iopub.status.idle": "2021-05-10T15:11:26.430709Z",
     "shell.execute_reply": "2021-05-10T15:11:26.428302Z",
     "shell.execute_reply.started": "2021-05-10T15:11:20.323246Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_160_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model=keras.applications.mobilenet.MobileNet(input_shape=(160, 160, 3),\n",
    "                                                  include_top=False,\n",
    "                                                  weights='imagenet', classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과거 훈련시킨 LSTM 모델(.h5)불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T15:11:26.438541Z",
     "iopub.status.busy": "2021-05-10T15:11:26.437543Z",
     "iopub.status.idle": "2021-05-10T15:11:30.997695Z",
     "shell.execute_reply": "2021-05-10T15:11:30.996809Z",
     "shell.execute_reply.started": "2021-05-10T15:11:26.438541Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=keras.models.load_model('210508_vc_MobileNet_model_epoch100.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비디오 영상에 텍스트 씌워 스트리밍\n",
    "* **`cv2.CAP_PROP_FRAME_COUNT`** : (동영상의) 총 프레임 개수\n",
    "* **`cv2.CAP_PROP_POS_FRAMES`** : 현재 프레임 개수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 투입 스트리밍, 산출 파일 지정\n",
    "* **주의!** 투입할 스트리밍 영상의 프레임 수는 반드시 **30**이어야 합니다. 29.97 안됩니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T15:11:31.006670Z",
     "iopub.status.busy": "2021-05-10T15:11:31.005672Z",
     "iopub.status.idle": "2021-05-10T15:11:31.030604Z",
     "shell.execute_reply": "2021-05-10T15:11:31.027613Z",
     "shell.execute_reply.started": "2021-05-10T15:11:31.006670Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_path=0 # 노트북 웹캠을 비디오 인풋으로 설정함\n",
    "output_path='output04.mp4' #저장할 결과 동영상 파일 이름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행!\n",
    "* 주의 : 인풋 비디오(input_path)는 반드시 30.0 fps여야 합니다. 29.97, 27.0, 24.0 안됩니다.\n",
    "* 스트리밍이 지속되는 한은 계속해서 영상이 송출됩니다. 따라서, 도중에 중단하려면 ESC 키를 누르세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T15:14:45.397034Z",
     "iopub.status.busy": "2021-05-10T15:14:45.397034Z",
     "iopub.status.idle": "2021-05-10T15:15:54.929754Z",
     "shell.execute_reply": "2021-05-10T15:15:54.927760Z",
     "shell.execute_reply.started": "2021-05-10T15:14:45.397034Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps : 30.0\n",
      "preds:[[0.00126779 0.99873227]]\n",
      "Results = [[nan nan]]\n",
      "Maximum Probability : nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-356aaa612a0a>:65: RuntimeWarning: Mean of empty slice.\n",
      "  results=np.array(Q)[:i].mean(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[[0.00121148 0.99878854]]\n",
      "Results = [[0.00126779 0.99873227]]\n",
      "Maximum Probability : 0.9987322688102722\n",
      "\n",
      "preds:[[0.01842158 0.98157835]]\n",
      "Results = [[0.00123964 0.9987604 ]]\n",
      "Maximum Probability : 0.9987604022026062\n",
      "\n",
      "preds:[[0.00956469 0.99043536]]\n",
      "Results = [[0.00696695 0.9930331 ]]\n",
      "Maximum Probability : 0.9930331110954285\n",
      "\n",
      "preds:[[0.00848091 0.99151903]]\n",
      "Results = [[0.00761638 0.99238366]]\n",
      "Maximum Probability : 0.9923836588859558\n",
      "\n",
      "preds:[[0.00283711 0.9971629 ]]\n",
      "Results = [[0.00778929 0.99221075]]\n",
      "Maximum Probability : 0.9922107458114624\n",
      "\n",
      "preds:[[0.00244105 0.99755895]]\n",
      "Results = [[0.00810315 0.9918968 ]]\n",
      "Maximum Probability : 0.9918968081474304\n",
      "\n",
      "preds:[[0.01611286 0.98388714]]\n",
      "Results = [[0.00834907 0.9916509 ]]\n",
      "Maximum Probability : 0.9916508793830872\n",
      "\n",
      "preds:[[0.0139117  0.98608834]]\n",
      "Results = [[0.00788732 0.99211264]]\n",
      "Maximum Probability : 0.9921126365661621\n",
      "\n",
      "ESC키를 눌렀습니다. 녹화를 종료합니다.\n",
      "종료 처리되었습니다. 메모리를 해제합니다.\n"
     ]
    }
   ],
   "source": [
    "#. ----- 비디오 스트리밍을 불러오기 & 초기설정 -----\n",
    "vc=cv2.VideoCapture(input_path)\n",
    "fps=vc.get(cv2.CAP_PROP_FPS) # input_path의 초당 프레임 수 인식. fps=30.0\n",
    "print(f'fps : {fps}')\n",
    "\n",
    "writer=None\n",
    "(W, H)=(None, None)\n",
    "i=0 # 비디오 초 번호. While loop를 돌아가는 회차\n",
    "Q=deque(maxlen=128) \n",
    "\n",
    "video_frm_ar=np.zeros((1, int(fps), 160, 160, 3), dtype=np.float) #frames\n",
    "frame_counter=0 # 1초당 프레임 번호. 1~30\n",
    "frame_list=[] \n",
    "preds=None\n",
    "maxprob=None\n",
    "\n",
    "#. While loop : 스트리밍이 끝날 때까지 프레임 추출 반복문 시작\n",
    "# ----- 스트리밍 동영상들을 (30, 160, 160, 3)으로 저장하기 시작 -----\n",
    "while True: \n",
    "    frame_counter+=1\n",
    "    grabbed, frm=vc.read() # 비디오를 1개 프레임씩 읽는다.\n",
    "    #> grabbed=True, frm=프레임별 넘파이 배열. (240, 320, 3)\n",
    "    \n",
    "    if not grabbed: # 프레임이 안 잡힐 경우\n",
    "        print('프레임이 없습니다. 스트리밍을 종료합니다.')\n",
    "        break\n",
    "            \n",
    "    if fps!=30: #비디오 fps가 30이 아니면 루프를 돌지 않기로 한다.\n",
    "        print('비디오의 초당 프레임이 30이 아닙니다. fps=30으로 맞춰주세요.')\n",
    "        break\n",
    "        \n",
    "    if W is None or H is None: # 프레임 이미지 폭(W), 높이(H)를 동영상에서\n",
    "        (H, W)=frm.shape[:2]\n",
    "            \n",
    "    output=frm.copy() #비디오 프레임을 그대로 복사. 저장/출력할 .mp4 파일로\n",
    "    \n",
    "    frame=resize(frm, (160, 160, 3)) #> input 배열을 (160, 160, 3)으로 변환\n",
    "    frame_list.append(frame) #각 프레임 배열 (160, 160, 3)이 append 된다.\n",
    "        \n",
    "    if frame_counter>=fps: #프레임 카운터가 30이 된 순간. len(frame_list)==30이 된 순간.\n",
    "        #. ----- 1초=30프레임마다 묶어서 예측(.predict) -----\n",
    "        #. ----- 1초 동안 (1, 30, 160, 160, 3) 배열을 만들어 모델에 투입 ---\n",
    "        #. ----- 예측 결과(1초)를 output에 씌워 준다. -----\n",
    "        # 그러기 위해서는 30개씩 append한 리스트를 넘파이화 -> 예측 -> 리스트 초기화 과정이 필요\n",
    "        frame_ar=np.array(frame_list, dtype=np.float16) #> 30개의 원소가 든 리스트를 변환. (30, 160, 160, 3)\n",
    "        frame_list=[] #30프레임이 채워질 때마다 넘파이 배열로 변환을 마친 프레임 리스트는 초기화 해 준다.\n",
    "            \n",
    "        if(np.max(frame_ar)>1): # 넘파이 배열의 RGB 값을 스케일링\n",
    "            frame_ar=frame_ar/255.0\n",
    "            \n",
    "        #video_frm_ar[i][:]=frame_ar #> (i, fps, 160, 160, 3). i번째 1초짜리 영상(30프레임) 배열 파일이 된다.\n",
    "        #print(video_frm_ar.shape)\n",
    "        \n",
    "        #MobileNet로 초당 프레임 이미지 배열로부터 특성 추출 : (1*30, 5, 5, 1024)\n",
    "        pred_imgarr=base_model.predict(frame_ar) #> (30, 5, 5, 1024)\n",
    "        # 추출된 특성 배열들을 1차원으로 변환 : (1, 30, 5*5*1024)\n",
    "        pred_imgarr_dim=pred_imgarr.reshape(1, pred_imgarr.shape[0], 5*5*1024)#> (1, 30, 25600)\n",
    "        # 각 프레임 폭력 여부 예측값을 0에 저장\n",
    "        preds=model.predict(pred_imgarr_dim) #> (True, 0.99) : (폭력여부, 폭력확률)\n",
    "        print(f'preds:{preds}')\n",
    "        Q.append(preds) #> Deque Q에 리스트처럼 예측값을 추가함\n",
    "    \n",
    "        # 지난 5초간의 폭력 확률 평균을 result로 한다.\n",
    "        if i<5:\n",
    "            results=np.array(Q)[:i].mean(axis=0)\n",
    "        else:\n",
    "            results=np.array(Q)[(i-5):i].mean(axis=0)\n",
    "        #results=np.array(Q).mean(axis=0)\n",
    "        print(f'Results = {results}') #> ex : (0.6, 0.650)\n",
    "            \n",
    "        #예측 결과에서 최대폭력확률값\n",
    "        maxprob=np.max(results) #> 가장 높은 값을 선택함\n",
    "        print(f'Maximum Probability : {maxprob}')\n",
    "        print('')\n",
    "            \n",
    "        rest=1-maxprob # 폭력이 아닐 확률\n",
    "        diff=maxprob-rest # 폭력일 확률과 폭력이 아닐 확률의 차이\n",
    "        th=100\n",
    "            \n",
    "        if diff>0.80: # 폭력일 확률과 아닐 확률의 차이가 0.8 이상이면\n",
    "            th=diff #근거가?\n",
    "        \n",
    "        frame_counter=0 #> 1초(30프레임)가 경과했으므로 frame_counter=0으로 리셋\n",
    "        i+=1 #> 1초 경과 의미\n",
    "        # frame_counter==30이 되면 0으로 돌아가 위 루프를 반복해 준다.\n",
    "                \n",
    "    # ----- output에 씌울 자막 설정하기 -----\n",
    "    # 30프레임(1초)마다 갱신된 값이 output에 씌워지게 된다\n",
    "    font1=ImageFont.truetype('fonts/Raleway-ExtraBold.ttf', 24)\n",
    "    font2=ImageFont.truetype('fonts/Raleway-ExtraBold.ttf', 48)\n",
    "    \n",
    "    if preds is not None and maxprob is not None: # 예측값이 발생한 후부터\n",
    "        if (preds[0][1])<th : #> 폭력일 확률이 th보다 작으면 정상\n",
    "            text1_1='Normal'\n",
    "            text1_2='{:.2f}%'.format(100-(maxprob*100))\n",
    "            img_pil=Image.fromarray(output)\n",
    "            draw=ImageDraw.Draw(img_pil)\n",
    "            draw.text((int(0.025*W), int(0.025*H)), text1_1, font=font1, fill=(0,255,0,0))\n",
    "            draw.text((int(0.025*W), int(0.095*H)), text1_2, font=font2, fill=(0,255,0,0))\n",
    "            output=np.array(img_pil)\n",
    "            # cv2.putText(이미지파일, 출력문자, 시작위치좌표(좌측하단), 폰트, 폰트크기, 폰트색상, 폰트두께)\n",
    "                \n",
    "        else : #> 폭력일 확률이 th보다 크면 폭력 취급\n",
    "            text2_1='Violence Alert!'\n",
    "            text2_2='{:.2f}%'.format(maxprob*100)\n",
    "            img_pil=Image.fromarray(output)\n",
    "            draw=ImageDraw.Draw(img_pil)\n",
    "            draw.text((int(0.025*W), int(0.025*H)), text2_1, font=font1, fill=(0,0,255,0))\n",
    "            draw.text((int(0.025*W), int(0.095*H)), text2_2, font=font2, fill=(0,0,255,0))\n",
    "            output=np.array(img_pil) \n",
    "        \n",
    "    # 자막이 씌워진 동영상을 writer로 저장함\n",
    "    if writer is None:\n",
    "        fourcc=cv2.VideoWriter_fourcc(*'DIVX')\n",
    "        writer=cv2.VideoWriter(output_path, fourcc, 30, (W, H), True)\n",
    "            \n",
    "    # 아웃풋을 새창으로 열어 보여주기\n",
    "    cv2.imshow('This is output', output)\n",
    "    writer.write(output) #output_path로 output 객체를 저장함\n",
    "        \n",
    "    key=cv2.waitKey(round(1000/fps)) # 프레임-다음 프레임 사이 간격\n",
    "    if key==27: # esc 키를 누르면 루프로부터 벗어나고 output 파일이 저장됨\n",
    "        print('ESC키를 눌렀습니다. 녹화를 종료합니다.')\n",
    "        break\n",
    "    \n",
    "print('종료 처리되었습니다. 메모리를 해제합니다.')\n",
    "writer.release()\n",
    "vc.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
