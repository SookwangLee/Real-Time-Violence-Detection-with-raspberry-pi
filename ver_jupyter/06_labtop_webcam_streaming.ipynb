{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. Actual Use : Violence detection for laptop webcam streaming\n",
    "* By using MobileNet base model & trained LSTM model, we can detect violent behavior of streaming video(laptop webcam)\n",
    "* **`Before run this file, Please check this`**:\n",
    "    * 01_video-to-numpy-save.ipynb\n",
    "    * 02_create-numpy-datasets_training-test.ipynb\n",
    "    * 03_MobileNet.ipynb\n",
    "    * 04_MobileNet_LSTM_model.ipynb\n",
    "* **`Are those files exist on there?`** Those files were made by 01~04_MobileNet.ipynb files.\n",
    "    * Trained LSTM model : 210512_MobileNet_model_epoch100.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T15:10:53.236116Z",
     "iopub.status.busy": "2021-05-10T15:10:53.236116Z",
     "iopub.status.idle": "2021-05-10T15:11:20.320255Z",
     "shell.execute_reply": "2021-05-10T15:11:20.314374Z",
     "shell.execute_reply.started": "2021-05-10T15:10:53.236116Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 # openCV 4.5.1\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time \n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize \n",
    "from PIL import Image, ImageFont, ImageDraw # add caption by using custom font\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06-A. Load Model Files\n",
    "* **`base_model`** : MobileNet\n",
    "* **`model`** : trained LSTM model file. `210512_MobileNet_model_epoch100.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. base_model : MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T15:11:20.323246Z",
     "iopub.status.busy": "2021-05-10T15:11:20.323246Z",
     "iopub.status.idle": "2021-05-10T15:11:26.430709Z",
     "shell.execute_reply": "2021-05-10T15:11:26.428302Z",
     "shell.execute_reply.started": "2021-05-10T15:11:20.323246Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_160_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model=keras.applications.mobilenet.MobileNet(input_shape=(160, 160, 3),\n",
    "                                                  include_top=False,\n",
    "                                                  weights='imagenet', classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. model : trained LSTM model(.h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T15:11:26.438541Z",
     "iopub.status.busy": "2021-05-10T15:11:26.437543Z",
     "iopub.status.idle": "2021-05-10T15:11:30.997695Z",
     "shell.execute_reply": "2021-05-10T15:11:30.996809Z",
     "shell.execute_reply.started": "2021-05-10T15:11:26.438541Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=keras.models.load_model('210512_MobileNet_model_epoch100.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06-B. Add caption to streaming screen & Save output video file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting : Input path & Output path\n",
    "* **`input_path`** : input laptop webcam\n",
    "* **`output_path`** : You'll save output video file in output_path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T15:11:31.006670Z",
     "iopub.status.busy": "2021-05-10T15:11:31.005672Z",
     "iopub.status.idle": "2021-05-10T15:11:31.030604Z",
     "shell.execute_reply": "2021-05-10T15:11:31.027613Z",
     "shell.execute_reply.started": "2021-05-10T15:11:31.006670Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_path=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path='output04.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Distinguish Violence True or False & Add caption on Video file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-10T15:14:45.397034Z",
     "iopub.status.busy": "2021-05-10T15:14:45.397034Z",
     "iopub.status.idle": "2021-05-10T15:15:54.929754Z",
     "shell.execute_reply": "2021-05-10T15:15:54.927760Z",
     "shell.execute_reply.started": "2021-05-10T15:14:45.397034Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fps : 30.0\n",
      "preds:[[0.00126779 0.99873227]]\n",
      "Results = [[nan nan]]\n",
      "Maximum Probability : nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-356aaa612a0a>:65: RuntimeWarning: Mean of empty slice.\n",
      "  results=np.array(Q)[:i].mean(axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preds:[[0.00121148 0.99878854]]\n",
      "Results = [[0.00126779 0.99873227]]\n",
      "Maximum Probability : 0.9987322688102722\n",
      "\n",
      "preds:[[0.01842158 0.98157835]]\n",
      "Results = [[0.00123964 0.9987604 ]]\n",
      "Maximum Probability : 0.9987604022026062\n",
      "\n",
      "preds:[[0.00956469 0.99043536]]\n",
      "Results = [[0.00696695 0.9930331 ]]\n",
      "Maximum Probability : 0.9930331110954285\n",
      "\n",
      "preds:[[0.00848091 0.99151903]]\n",
      "Results = [[0.00761638 0.99238366]]\n",
      "Maximum Probability : 0.9923836588859558\n",
      "\n",
      "preds:[[0.00283711 0.9971629 ]]\n",
      "Results = [[0.00778929 0.99221075]]\n",
      "Maximum Probability : 0.9922107458114624\n",
      "\n",
      "preds:[[0.00244105 0.99755895]]\n",
      "Results = [[0.00810315 0.9918968 ]]\n",
      "Maximum Probability : 0.9918968081474304\n",
      "\n",
      "preds:[[0.01611286 0.98388714]]\n",
      "Results = [[0.00834907 0.9916509 ]]\n",
      "Maximum Probability : 0.9916508793830872\n",
      "\n",
      "preds:[[0.0139117  0.98608834]]\n",
      "Results = [[0.00788732 0.99211264]]\n",
      "Maximum Probability : 0.9921126365661621\n",
      "\n",
      "ESC키를 눌렀습니다. 녹화를 종료합니다.\n",
      "종료 처리되었습니다. 메모리를 해제합니다.\n"
     ]
    }
   ],
   "source": [
    "vid=cv2.VideoCapture(input_path)\n",
    "fps=vid.get(cv2.CAP_PROP_FPS) # recognize frames per secone(fps) of input_path video file.\n",
    "print(f'fps : {fps}') # print fps.\n",
    "\n",
    "writer=None\n",
    "(W, H)=(None, None)\n",
    "i=0 # number of seconds in video = The number of times that how many operated while loop .\n",
    "Q=deque(maxlen=128) \n",
    "\n",
    "video_frm_ar=np.zeros((1, int(fps), 160, 160, 3), dtype=np.float) #frames\n",
    "frame_counter=0 # frame number in 1 second. 1~30\n",
    "frame_list=[] \n",
    "preds=None\n",
    "maxprob=None\n",
    "\n",
    "#. While loop : Until the end of input video, it read frame, extract features, predict violence True or False.\n",
    "# ----- Reshape & Save frame img as (30, 160, 160, 3) Numpy array  -----\n",
    "while True: \n",
    "    frame_counter+=1\n",
    "    grabbed, frm=vid.read()  # read each frame img. grabbed=True, frm=frm img. ex: (240, 320, 3)\n",
    "    \n",
    "    if not grabbed:\n",
    "        print('There is no frame. Streaming ends.')\n",
    "        break\n",
    "            \n",
    "    if fps!=30: \n",
    "        print('Please set fps=30')\n",
    "        break\n",
    "        \n",
    "    if W is None or H is None: # W: width, H: height of frame img\n",
    "        (H, W)=frm.shape[:2]\n",
    "            \n",
    "    output=frm.copy() # It is necessary for streaming captioned output video, and to save that.\n",
    "    \n",
    "    frame=resize(frm, (160, 160, 3)) #> Resize frame img array to (160, 160, 3)\n",
    "    frame_list.append(frame) # Append each frame img Numpy array : element is (160, 160, 3) Numpy array.\n",
    "    \n",
    "    if frame_counter>=fps: # fps=30 et al\n",
    "        #. ----- we'll predict violence True or False every 30 frame -----\n",
    "        #. ----- Insert (1, 30, 160, 160, 3) Numpy array to LSTM model ---\n",
    "        #. ----- We'll renew predict result caption on output video every 1 second. -----\n",
    "        # 30-element-appended list -> Transform to Numpy array -> Predict -> Initialize list (repeat)\n",
    "        frame_ar=np.array(frame_list, dtype=np.float16) #> (30, 160, 160, 3)\n",
    "        frame_list=[] # Initialize frame list when frame_counter is same or exceed 30, after transforming to Numpy array.\n",
    "            \n",
    "        if(np.max(frame_ar)>1): # Scaling RGB value in Numpy array\n",
    "            frame_ar=frame_ar/255.0\n",
    "            \n",
    "        pred_imgarr=base_model.predict(frame_ar) #> Extract features from each frame img by using MobileNet. (30, 5, 5, 1024)\n",
    "        pred_imgarr_dim=pred_imgarr.reshape(1, pred_imgarr.shape[0], 5*5*1024)#> (1, 30, 25600)\n",
    "        \n",
    "        preds=model.predict(pred_imgarr_dim) #> (True, 0.99) : (Violence True or False, Probability of Violence)\n",
    "        print(f'preds:{preds}')\n",
    "        Q.append(preds) #> Deque Q\n",
    "    \n",
    "        # Predict Result : Average of Violence probability in last 5 second\n",
    "        if i<5:\n",
    "            results=np.array(Q)[:i].mean(axis=0)\n",
    "        else:\n",
    "            results=np.array(Q)[(i-5):i].mean(axis=0)\n",
    "        \n",
    "        print(f'Results = {results}') #> ex : (0.6, 0.650)\n",
    "            \n",
    "        maxprob=np.max(results) #> Select Maximum Probability\n",
    "        print(f'Maximum Probability : {maxprob}')\n",
    "        print('')\n",
    "            \n",
    "        rest=1-maxprob # Probability of Non-Violence\n",
    "        diff=maxprob-rest # Difference between Probability of Violence and Non-Violence's\n",
    "        th=100\n",
    "            \n",
    "        if diff>0.80:\n",
    "            th=diff # ?? What is supporting basis?\n",
    "        \n",
    "        frame_counter=0 #> Initialize frame_counter to 0\n",
    "        i+=1 #> 1 second elapsed\n",
    "        \n",
    "        # When frame_counter>=30, Initialize frame_counter to 0, and repeat above while loop.\n",
    "                \n",
    "    # ----- Setting caption option of output video -----\n",
    "    # Renewed caption is added every 30 frames(if fps=30, it means 1 second.)\n",
    "    font1=ImageFont.truetype('fonts/Raleway-ExtraBold.ttf', 24) # font option\n",
    "    font2=ImageFont.truetype('fonts/Raleway-ExtraBold.ttf', 48) # font option\n",
    "    \n",
    "    if preds is not None and maxprob is not None:\n",
    "        if (preds[0][1])<th : #> if violence probability < th, Violence=False (Normal, Green Caption)\n",
    "            text1_1='Normal'\n",
    "            text1_2='{:.2f}%'.format(100-(maxprob*100))\n",
    "            img_pil=Image.fromarray(output)\n",
    "            draw=ImageDraw.Draw(img_pil)\n",
    "            draw.text((int(0.025*W), int(0.025*H)), text1_1, font=font1, fill=(0,255,0,0))\n",
    "            draw.text((int(0.025*W), int(0.095*H)), text1_2, font=font2, fill=(0,255,0,0))\n",
    "            output=np.array(img_pil)\n",
    "                \n",
    "        else : #> if violence probability > th, Violence=True (Violence Alert!, Red Caption)\n",
    "            text2_1='Violence Alert!'\n",
    "            text2_2='{:.2f}%'.format(maxprob*100)\n",
    "            img_pil=Image.fromarray(output)\n",
    "            draw=ImageDraw.Draw(img_pil)\n",
    "            draw.text((int(0.025*W), int(0.025*H)), text2_1, font=font1, fill=(0,0,255,0))\n",
    "            draw.text((int(0.025*W), int(0.095*H)), text2_2, font=font2, fill=(0,0,255,0))\n",
    "            output=np.array(img_pil) \n",
    "        \n",
    "    # Save captioned video file by using 'writer'\n",
    "    if writer is None:\n",
    "        fourcc=cv2.VideoWriter_fourcc(*'DIVX')\n",
    "        writer=cv2.VideoWriter(output_path, fourcc, 30, (W, H), True)\n",
    "            \n",
    "    cv2.imshow('This is output', output) # View output in new Window.\n",
    "    writer.write(output) # Save output in output_path\n",
    "        \n",
    "    key=cv2.waitKey(round(1000/fps)) # time gap of frame and next frame\n",
    "    if key==27: # If you press ESC key, While loop will be breaked and output file will be saved.\n",
    "        print('ESC is pressed. Video recording ends.')\n",
    "        break\n",
    "    \n",
    "print('Video recording ends. Release Memory.')  #Output file will be saved.\n",
    "writer.release()\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
